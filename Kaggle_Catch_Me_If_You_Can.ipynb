{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score,make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('/Users/Roman/Documents/Machine_Learning_and_Data_Analysis.MPTI' +\n",
    "                '/6_course/User_Identification/Week_1/capstone_user_identification/kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#обучающая и тестовая выборка\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'),\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'),\n",
    "                      index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#объединение выборок\n",
    "train_test_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_df_sites = train_test_df[['site%d' % i for i in range(1, 11)]].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция для слияния списка списков\n",
    "def listmerge(lstlst):\n",
    "    whole_lst=[]\n",
    "    for lst in lstlst:\n",
    "        whole_lst.extend(lst)\n",
    "    return whole_lst\n",
    "\n",
    "#функция, подготавлювающая параметры для создания разреженной матрицы\n",
    "def param_for_csr(X,session_length=10):\n",
    "    indices = np.array(listmerge(X))\n",
    "    indptr = [i*session_length for i in range(int(indices.size/session_length+1))]\n",
    "    data = np.array([1]*indices.size)\n",
    "    return data,indices,indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#создания разреженной матрицы частот сайтов\n",
    "train_test_sparse = csr_matrix(param_for_csr(train_test_df_sites.values,session_length=10))[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция для гененрации признаков\n",
    "def more_features(frame):\n",
    "    sites = frame[['site%d' % i for i in range(1, 11)]].fillna(0).astype('int').values\n",
    "    times_str = frame[['time%d' % i for i in range(1, 11)]].fillna(0).values\n",
    "    \n",
    "    times_format = []\n",
    "    for session in times_str:\n",
    "        times_format.append([datetime.strptime(t,\"%Y-%m-%d %H:%M:%S\") for t in session if t!=0])\n",
    "     \n",
    "    session_timespan = []\n",
    "    start_hour = []\n",
    "    day_of_week = []\n",
    "    max_delta = []\n",
    "    num_of_small_time = []\n",
    "    for session in times_format:\n",
    "        deltas_list = [(session[i+1]-session[i]).seconds for i in range(len(session)-1)]\n",
    "        \n",
    "        session_timespan.append(sum(deltas_list))\n",
    "        start_hour.append(session[0].hour)\n",
    "        day_of_week.append(session[0].weekday())\n",
    "        if len(deltas_list)!= 0:\n",
    "            max_delta.append(max(deltas_list))\n",
    "        else: \n",
    "            max_delta.append(0)\n",
    "            \n",
    "        num_of_small_time.append(sum([1  for d in deltas_list if (d<20 and d>5)]))\n",
    "    \n",
    "    unique_sites = [] \n",
    "    top_site_shares = [] \n",
    "\n",
    "    \n",
    "    for session in sites:\n",
    "        unique_sites.append(np.unique([session[i]  for i in range(len(session)) if session[i]!=0]).size)   \n",
    "        top_site_shares.append(sum([1  for top in (range(1,31)) if list(session).count(top)!=0])/np.unique([session[i]  for i in range(len(session)) if session[i]!=0]).size)\n",
    "       \n",
    "    return np.hstack(\n",
    "        [np.array(session_timespan)[:,np.newaxis],np.array(start_hour)[:,np.newaxis],\n",
    "        np.array(day_of_week)[:,np.newaxis], np.array(unique_sites)[:,np.newaxis],\n",
    "        np.array(top_site_shares)[:,np.newaxis], np.array(max_delta)[:,np.newaxis],\n",
    "        np.array(num_of_small_time)[:,np.newaxis]]\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = more_features(train_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция для нормирования признаков\n",
    "def norm(X):\n",
    "    m = np.mean(X)\n",
    "    st = np.std(X)\n",
    "    return [(x-m)/st for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_norm = pd.DataFrame(features).apply(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#добавление признаков\n",
    "train_test_sparse_extended = hstack([train_test_sparse,features_norm.values]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_extended  = train_test_sparse[:len(train_df)]\n",
    "X_test_sparse_extended  = train_test_sparse[len(train_df):]\n",
    "y = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#создание обучающей и валидационной выборки\n",
    "train_share = int(.7 * X_train_sparse_extended.shape[0])\n",
    "X_train, y_train = X_train_sparse_extended[:train_share, :], y[:train_share]\n",
    "X_valid, y_valid  = X_train_sparse_extended[train_share:, :], y[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#логит с l2\n",
    "logit = LogisticRegression(random_state=17,n_jobs=-1,penalty='l2')\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_proba = logit.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95831249715783184"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC_valid = roc_auc_score(y_valid, logit_proba[:,1])\n",
    "ROC_AUC_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_values = np.linspace(1,2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_auc_score_proba(y_true, proba):\n",
    "    return roc_auc_score(y_true, proba[:, 1])\n",
    "\n",
    "auc = make_scorer(roc_auc_score_proba, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([ 1.     ,  1.05263,  1.10526,  1.15789,  1.21053,  1.26316,\n",
       "        1.31579,  1.36842,  1.42105,  1.47368,  1.52632,  1.57895,\n",
       "        1.63158,  1.68421,  1.73684,  1.78947,  1.84211,  1.89474,\n",
       "        1.94737,  2.     ]),\n",
       "           class_weight=None,\n",
       "           cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=-1, penalty='l2',\n",
       "           random_state=17, refit=True,\n",
       "           scoring=make_scorer(roc_auc_score_proba, needs_proba=True),\n",
       "           solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#подбор l2\n",
    "logitCV = LogisticRegressionCV(Cs = C_values,random_state=17,n_jobs=-1,penalty='l2',scoring=auc ,cv=skf)\n",
    "logitCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logitCV_proba = logitCV.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95848061163994092"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#результат на валидационной выборки \n",
    "ROC_AUC_valid = roc_auc_score(y_valid, logitCV_proba[:,1])\n",
    "ROC_AUC_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.21, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучение на всей обучающей выборки с оптимальным коэффициентом С\n",
    "logit1 = LogisticRegression(C = 1.21,random_state=17,n_jobs=-1,penalty='l2')\n",
    "logit1.fit(X_train_sparse_extended, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([ 1.     ,  1.05263,  1.10526,  1.15789,  1.21053,  1.26316,\n",
       "        1.31579,  1.36842,  1.42105,  1.47368,  1.52632,  1.57895,\n",
       "        1.63158,  1.68421,  1.73684,  1.78947,  1.84211,  1.89474,\n",
       "        1.94737,  2.     ]),\n",
       "           class_weight=None,\n",
       "           cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=-1, penalty='l1',\n",
       "           random_state=17, refit=True,\n",
       "           scoring=make_scorer(roc_auc_score_proba, needs_proba=True),\n",
       "           solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#подбор l1\n",
    "logitCV2 = LogisticRegressionCV(Cs = C_values,random_state=17,n_jobs=-1,penalty='l1',\n",
    "                                scoring=auc ,cv=skf,solver='liblinear')\n",
    "logitCV2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logitCV2_proba = logitCV2.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95718107461522317"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#результат на валидационной выборки \n",
    "ROC_AUC_valid = roc_auc_score(y_valid, logitCV2_proba[:,1])\n",
    "ROC_AUC_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.52631579, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=17,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучение на всей обучающей выборки с оптимальным коэффициентом С\n",
    "logit2 = LogisticRegression(C = 1.52631579, random_state=17,n_jobs=-1,penalty='l1')\n",
    "logit2.fit(X_train_sparse_extended, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_test_proba1 = logit1.predict_proba(X_test_sparse_extended)[:,1]\n",
    "logit_test_proba2 = logit2.predict_proba(X_test_sparse_extended)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_proba1, os.path.join(PATH_TO_DATA,'predictions1.csv'))\n",
    "write_to_submission_file(logit_test_proba2, os.path.join(PATH_TO_DATA,'predictions2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
